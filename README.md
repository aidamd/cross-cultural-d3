This repository contains the annotation items used in an experiment of offensive language annotation across different global contexts.

The ```annotation-items.csv``` file contains all textual items selected from two Jigsaw datasets [1, 2].


[1] Jigsaw. Toxic comment classification challenge, 2018. Accessed:  2021-05-01. 

[2] Jigsaw.  Unintended bias in toxicity classification, 2019.  Accessed:  2021-05-01.
